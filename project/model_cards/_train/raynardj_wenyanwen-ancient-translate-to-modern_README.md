---
language:
- zh
- zh
tags:
- translation
- å¤æ–‡
- æ–‡è¨€æ–‡
- ancient
- classical
widget:
- text: "æ­¤è¯šå±æ€¥å­˜äº¡ä¹‹ç§‹ä¹Ÿ"

---

# From Classical(ancient) Chinese to Modern Chinese
> This model translate Classical(ancient) Chinese to Modern Chinese, so I guess who's interested in the problemset can speak at least modern Chinese, hence... let me continue the documentation in Chinese

# æ–‡è¨€æ–‡ï¼ˆå¤æ–‡ï¼‰åˆ°ç°ä»£æ–‡çš„ç¿»è¯‘å™¨
> è¿™ä¸ªæ¨¡å‹å·²æœ‰åšæˆåº”ç”¨ï¼Œ [ã€éšæ— æ¶¯ã€‘](https://huggingface.co/spaces/raynardj/duguwen-classical-chinese-to-morden-translate)æ˜¯ä¸€ä¸ªhuggingface spaces + streamlit çš„å¤æ–‡é˜…è¯»åº”ç”¨ï¼ˆå«æµ·é‡ä¹¦ç±ï¼‰ï¼Œ å¯ä»¥åœ¨é˜…è¯»æ—¶ç¿»è¯‘
> è¾“å…¥æ–‡è¨€æ–‡ï¼Œ å¯ä»¥æ˜¯æ–­å¥ æˆ–è€… æœªæ–­å¥çš„æ–‡è¨€æ–‡ï¼Œ æ¨¡å‹ä¼šé¢„æµ‹ç°ä»£æ–‡çš„è¡¨è¿°ã€‚ å…¶ä»–æ¨¡å‹ï¼š
* ä»[ç°ä»£æ–‡ç¿»è¯‘åˆ°æ–‡è¨€æ–‡](https://huggingface.co/raynardj/wenyanwen-chinese-translate-to-ancient)

> ä»æ–‡è¨€æ–‡åˆ°ç°ä»£æ–‡çš„ç¿»è¯‘å™¨, æ¬¢è¿å‰å¾€[æˆ‘çš„githubæ–‡è¨€è¯—è¯é¡¹ç›®é¡µé¢æ¢è®¨ã€åŠ â­ï¸ ](https://github.com/raynardj/yuan)

> è®­ç»ƒè¯­æ–™æ˜¯å°±æ˜¯ä¹åå¤šä¸‡å¥å¥å¯¹ï¼Œ [æ•°æ®é›†é“¾æ¥ğŸ“š](https://github.com/BangBOOM/Classical-Chinese)ã€‚ è®­ç»ƒæ—¶sourceåºåˆ—ï¼ˆå¤æ–‡åºåˆ—ï¼‰ï¼Œ æŒ‰ç…§50%çš„æ¦‚ç‡æ•´å¥å»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·ã€‚

## æ¨èçš„inference é€šé“
**æ³¨æ„**
* ä½ å¿…é¡»å°†```generate```å‡½æ•°çš„```eos_token_id```è®¾ç½®ä¸º102å°±å¯ä»¥ç¿»è¯‘å‡ºå®Œæ•´çš„è¯­å¥ï¼Œ ä¸ç„¶ç¿»è¯‘å®Œäº†ä¼šæœ‰æ®‹ç•™çš„è¯­å¥(å› ä¸ºåšç†µçš„æ—¶å€™ç”¨padæ ‡ç­¾=-100å¯¼è‡´)ã€‚
ç›®å‰huggingface é¡µé¢ä¸ŠcomputeæŒ‰é’®ä¼šæœ‰è¿™ä¸ªé—®é¢˜ï¼Œ æ¨èä½¿ç”¨ä»¥ä¸‹ä»£ç æ¥å¾—åˆ°ç¿»è¯‘ç»“æœ
* è¯·è®¾ç½®```generate```çš„å‚æ•°```num_beams>=3```, ä»¥è¾¾åˆ°è¾ƒå¥½çš„ç¿»è¯‘æ•ˆæœ
* è¯·è®¾ç½®```generate```çš„å‚æ•°```max_length```256ï¼Œ ä¸ç„¶ç»“æœä¼šåƒæ‰å¥å­
```python
from transformers import (
  EncoderDecoderModel,
  AutoTokenizer
)
PRETRAINED = "raynardj/wenyanwen-ancient-translate-to-modern"
tokenizer = AutoTokenizer.from_pretrained(PRETRAINED)
model = EncoderDecoderModel.from_pretrained(PRETRAINED)
def inference(text):
    tk_kwargs = dict(
      truncation=True,
      max_length=128,
      padding="max_length",
      return_tensors='pt')
   
    inputs = tokenizer([text,],**tk_kwargs)
    with torch.no_grad():
        return tokenizer.batch_decode(
            model.generate(
            inputs.input_ids,
            attention_mask=inputs.attention_mask,
            num_beams=3,
            max_length=256,
            bos_token_id=101,
            eos_token_id=tokenizer.sep_token_id,
            pad_token_id=tokenizer.pad_token_id,
        ), skip_special_tokens=True)
```

## ç›®å‰ç‰ˆæœ¬çš„æ¡ˆä¾‹
> å½“ç„¶ï¼Œ æ‹¿æ¯”è¾ƒç†ŸçŸ¥çš„è¯­å¥è¿‡æ¥ï¼Œ é€šå¸¸ä¼šæœ‰äº›è´»ç¬‘å¤§æ–¹çš„å¤±è¯¯ï¼Œ å¤§å®¶å¦‚æœæœ‰å¥½ç©çš„è°ƒæˆæ¡ˆä¾‹ï¼Œ ä¹Ÿæ¬¢è¿åé¦ˆ
```python
>>> inference('éæˆ‘æ—ç±»å…¶å¿ƒå¿…å¼‚')
['ä¸ æ˜¯ æˆ‘ ä»¬ çš„ æ— ç±» ï¼Œ ä»– ä»¬ çš„ å¿ƒ æ€ å¿… ç„¶ ä¸ åŒ ã€‚']
>>> inference('è‚‰é£Ÿè€…é„™æœªèƒ½è¿œè°‹')
['åƒ è‚‰ çš„ äºº é„™ é™‹ ï¼Œ ä¸ èƒ½ é•¿ è¿œ è°‹ åˆ’ ã€‚']
# è¿™é‡Œæˆ‘å¥½å‡ æ‰¹æ¨¡å‹éƒ½ç¿»ä¸å‡ºè¿™ä¸ª**è¾“**å­—ï¼ˆç”šè‡³æœ‰ä¸€ä¸ªç‰ˆæœ¬ç¿»æˆäº†ç§¦å§‹çš‡å’Œæ±‰æ­¦å¸ï¼‰ï¼Œ å¯èƒ½å¹¶ä¸æ˜¯å¾ˆå¤æœ´çš„ç”¨æ³•ï¼Œ 
>>> inference('æ±Ÿå±±å¦‚æ­¤å¤šå¨‡å¼•æ— æ•°è‹±é›„ç«æŠ˜è…°æƒœç§¦çš‡æ±‰æ­¦ç•¥è¾“æ–‡é‡‡å”å®—å®‹ç¥–ç¨é€Šé£éªš')
['æ±Ÿ å±± å¦‚ æ­¤ å¤š ï¼Œ æ‹› å¼• æ—  æ•° çš„ è‹± é›„ ï¼Œ ç« ç›¸ æŠ˜ è…° ï¼Œ å¯ æƒœ ç§¦ çš‡ ã€ æ±‰ æ­¦ ï¼Œ ç•¥ å¾® æœ‰ æ–‡ é‡‡ ï¼Œ å” å®— ã€ å®‹ ç¥– ç¨ ç¨ é€Š å‡º é£ é›… ã€‚']
>>> inference("æ¸…é£å¾æ¥æ°´æ³¢ä¸å…´")
['æ¸… é£ æ…¢ æ…¢ å¹ æ¥ ï¼Œ æ°´ æ³¢ ä¸ å…´ ã€‚']
>>> inference("æ— ä»–å”¯æ‰‹ç†Ÿå°”")
['æ²¡ æœ‰ åˆ« çš„ äº‹ ï¼Œ åª æ˜¯ æ‰‹ ç†Ÿ ç½¢ äº† ã€‚']
>>> inference("æ­¤è¯šå±æ€¥å­˜äº¡ä¹‹ç§‹ä¹Ÿ")
['è¿™ å® åœ¨ æ˜¯ å± æ€¥ å­˜ äº¡ çš„ æ—¶ å€™ ã€‚']
```

## å…¶ä»–æ–‡è¨€è¯—è¯çš„èµ„æº
* [é¡¹ç›®æºä»£ç  ğŸŒŸ, æ¬¢è¿+staræpr](https://github.com/raynardj/yuan)
* [è·¨è¯­ç§æœç´¢ ğŸ”](https://huggingface.co/raynardj/xlsearch-cross-lang-search-zh-vs-classicical-cn)
* [ç°ä»£æ–‡ç¿»è¯‘å¤æ±‰è¯­çš„æ¨¡å‹ â›°](https://huggingface.co/raynardj/wenyanwen-chinese-translate-to-ancient)
* [å¤æ±‰è¯­åˆ°ç°ä»£æ–‡çš„ç¿»è¯‘æ¨¡å‹, è¾“å…¥å¯ä»¥æ˜¯æœªæ–­å¥çš„å¥å­ ğŸš€](https://huggingface.co/raynardj/wenyanwen-ancient-translate-to-modern)
* [æ–­å¥æ¨¡å‹ ğŸ—¡](https://huggingface.co/raynardj/classical-chinese-punctuation-guwen-biaodian)
* [æ„å¢ƒå…³é”®è¯ å’Œ è—å¤´å†™è¯—ğŸ¤–](https://huggingface.co/raynardj/keywords-cangtou-chinese-poetry)