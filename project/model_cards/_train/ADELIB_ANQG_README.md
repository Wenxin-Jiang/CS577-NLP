Hugging Face's logo
Hugging Face
Search models, datasets, users...
Models
Datasets
Spaces
Docs
Solutions
Pricing




Mihakram
/
Arabic_Question_Generation Copied
like
0
Text2Text Generation
PyTorch
Transformers
Arabic

arxiv:2109.12068
t5
AutoTrain Compatible
Model card
Files and versions
Community
Arabic_Question_Generation
/
README.md
Mihakram's picture
Mihakram
Update README.md
9920e0d
14 minutes ago
raw
history
blame
contribute
delete
Safe
3.41 kB
---
language: 
- ar
widget:
- text: "context: Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠØ© Ø£Ùˆ Ø«ÙˆØ±Ø© Ø§Ù„Ù…Ù„ÙŠÙˆÙ† Ø´Ù‡ÙŠØ¯ØŒ Ø§Ù†Ø¯Ù„Ø¹Øª ÙÙŠ 1 Ù†ÙˆÙÙ…Ø¨Ø± 1954 Ø¶Ø¯ Ø§Ù„Ù…Ø³ØªØ¹Ù…Ø± Ø§Ù„ÙØ±Ù†Ø³ÙŠ ÙˆØ¯Ø§Ù…Øª 7 Ø³Ù†ÙˆØ§Øª ÙˆÙ†ØµÙ. Ø§Ø³ØªØ´Ù‡Ø¯ ÙÙŠÙ‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ù„ÙŠÙˆÙ† ÙˆÙ†ØµÙ Ù…Ù„ÙŠÙˆÙ† Ø¬Ø²Ø§Ø¦Ø±ÙŠ answer:  7 Ø³Ù†ÙˆØ§Øª ÙˆÙ†ØµÙ </s>
"
- text: "context: Ø§Ø³ÙƒØªÙ„Ù†Ø¯Ø§ Ø¯ÙˆÙ„Ø© ÙÙŠ Ø´Ù…Ø§Ù„ ØºØ±Ø¨ Ø£ÙˆØ±ÙˆØ¨Ø§ØŒ ØªØ¹ØªØ¨Ø± Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø±Ø¨Ø¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø© Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. ØªØ­ØªÙ„ Ø§Ù„Ø«Ù„Ø« Ø§Ù„Ø´Ù…Ø§Ù„ÙŠ Ù…Ù† Ø¬Ø²ÙŠØ±Ø© Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ§ Ø§Ù„Ø¹Ø¸Ù…Ù‰ ÙˆØªØ­Ø¯Ù‡Ø§ Ø¬Ù†ÙˆØ¨Ø§ Ø¥Ù†Ø¬Ù„ØªØ±Ø§ ÙˆÙŠØ­Ø¯Ù‡Ø§ Ø´Ø±Ù‚Ø§ Ø¨Ø­Ø± Ø§Ù„Ø´Ù…Ø§Ù„ ÙˆØºØ±Ø¨Ø§ Ø§Ù„Ù…Ø­ÙŠØ· Ø§Ù„Ø£Ø·Ù„Ø³ÙŠ. Ø¹Ø§ØµÙ…ØªÙ‡Ø§ Ø£Ø¯Ù†Ø¨Ø±Ø©ØŒ ÙˆØ£Ù‡Ù… Ù…Ø¯Ù†Ù‡Ø§ ÙˆØ£ÙƒØ¨Ø±Ù‡Ø§ Ù…Ø¯ÙŠÙ†Ø© ØºÙ„Ø§Ø³ÙƒÙˆ. ÙƒØ§Ù†Øª Ø§Ø³ÙƒØªÙ„Ù†Ø¯Ø§ Ù…Ù…Ù„ÙƒØ© Ù…Ø³ØªÙ‚Ù„Ø© Ø­ØªÙ‰ 1 Ù…Ø§ÙŠÙˆ 1707  answer:  Ø£Ø¯Ù†Ø¨Ø±Ø©  </s>"

- text: "context: Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ Ø£Ø¯ÙˆÙ„Ù Ù‡ØªÙ„Ø± ÙÙŠ 30 Ø£Ø¨Ø±ÙŠÙ„ 1945 Ù…Ù†ØªØ­Ø±Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªÙ†Ø§ÙˆÙ„ Ù…Ø§Ø¯Ø© Ø§Ù„Ø³ÙŠØ§Ù†ÙŠØ¯ Ø§Ù„Ø³Ø§Ù…Ø© ÙˆØ¥Ø·Ù„Ø§Ù‚ Ø§Ù„Ù†Ø§Ø± Ø¹Ù„Ù‰ Ù†ÙØ³Ù‡ ÙˆÙ‡ÙŠ Ø§Ù„Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„Ø© Ù„Ø·Ø±ÙŠÙ‚Ø© Ù…ÙˆØª Ø§Ù„Ø²Ø¹ÙŠÙ… Ø§Ù„Ù†Ø§Ø²ÙŠ answer: Ù…Ù†ØªØ­Ø±Ø§ </s>
"

---
# Arabic Question generation Model


This model is ready to use for **Question generation**, simply input the text and answer and the model will generate a question,  This model is a fine-tuned version of [AraT5-Base Model](https://huggingface.co/UBC-NLP/AraT5-base)
 

## Requirements
```
!pip install transformers
```


## Model in Action ğŸš€
```python
from transformers import AutoTokenizer,AutoModelForSeq2SeqLM
model = AutoModelForSeq2SeqLM.from_pretrained("Mihakram/Arabic_Question_Generation")
tokenizer = AutoTokenizer.from_pretrained("Mihakram/Arabic_Question_Generation")
def get_question(context,answer):
  text="context: " +context + " " + "answer: " + answer + " </s>"
  text_encoding = tokenizer.encode_plus(
      text,return_tensors="pt"
  )
  model.eval()
  generated_ids =  model.generate(
    input_ids=text_encoding['input_ids'],
    attention_mask=text_encoding['attention_mask'],
    max_length=64,
    num_beams=5,
    num_return_sequences=1
  )
  return tokenizer.decode(generated_ids[0],skip_special_tokens=True,clean_up_tokenization_spaces=True).replace('question: ',' ')
context="Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠØ© Ø£Ùˆ Ø«ÙˆØ±Ø© Ø§Ù„Ù…Ù„ÙŠÙˆÙ† Ø´Ù‡ÙŠØ¯ØŒ Ø§Ù†Ø¯Ù„Ø¹Øª ÙÙŠ 1 Ù†ÙˆÙÙ…Ø¨Ø± 1954 Ø¶Ø¯ Ø§Ù„Ù…Ø³ØªØ¹Ù…Ø± Ø§Ù„ÙØ±Ù†Ø³ÙŠ ÙˆØ¯Ø§Ù…Øª 7 Ø³Ù†ÙˆØ§Øª ÙˆÙ†ØµÙ. Ø§Ø³ØªØ´Ù‡Ø¯ ÙÙŠÙ‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ù„ÙŠÙˆÙ† ÙˆÙ†ØµÙ Ù…Ù„ÙŠÙˆÙ† Ø¬Ø²Ø§Ø¦Ø±ÙŠ"
answer =" 7 Ø³Ù†ÙˆØ§Øª ÙˆÙ†ØµÙ"
get_question(context,answer)
#output : question="ÙƒÙ… Ø§Ø³ØªÙ…Ø±Øª Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠØ©ØŸ " 
```

## Expriments
We report score with `NQG Scorer`.

If not special explanation, the size of the model defaults to "base".

### Metrics resaults
 Bleu 1|Bleu 2|Bleu 3|Bleu 4|METEOR|ROUGE-L|
------|------|------|------|------|-------|
54.67 |39.26 |30.34 |24.15 |25.43 |52.64  |

## References

The **Ara-T5** model was presented in [AraT5: Text-to-Text Transformers for Arabic Language Generation](https://arxiv.org/abs/2109.12068) by *El Moatez Billah Nagoudi, AbdelRahim Elmadany, Muhammad Abdul-Mageed* 

## Citation
If you want to cite this model you can use this:

```bibtex
@misc{Mihakram/,
  title={},
  author={Mihoubi, Ibrir},
  publisher={Hugging Face},
  journal={Hugging Face Hub},
  howpublished={\url{https://huggingface.co/}},
  year={2022}
}
```