---
language: 
- ar
tags:
- answer-aware-question-generation 
- question-generation
- QG
dataset:
- arabic_question_answering
widget:
- text: "context: Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠØ© Ø£Ùˆ Ø«ÙˆØ±Ø© Ø§Ù„Ù…Ù„ÙŠÙˆÙ† Ø´Ù‡ÙŠØ¯ØŒ Ø§Ù†Ø¯Ù„Ø¹Øª ÙÙŠ 1 Ù†ÙˆÙÙ…Ø¨Ø± 1954 Ø¶Ø¯ Ø§Ù„Ù…Ø³ØªØ¹Ù…Ø± Ø§Ù„ÙØ±Ù†Ø³ÙŠ ÙˆØ¯Ø§Ù…Øª 7 Ø³Ù†ÙˆØ§Øª ÙˆÙ†ØµÙ. Ø§Ø³ØªØ´Ù‡Ø¯ ÙÙŠÙ‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ù„ÙŠÙˆÙ† ÙˆÙ†ØµÙ Ù…Ù„ÙŠÙˆÙ† Ø¬Ø²Ø§Ø¦Ø±ÙŠ answer:  7 Ø³Ù†ÙˆØ§Øª ÙˆÙ†ØµÙ </s>
"
- text: "context: Ø§Ø³ÙƒØªÙ„Ù†Ø¯Ø§ Ø¯ÙˆÙ„Ø© ÙÙŠ Ø´Ù…Ø§Ù„ ØºØ±Ø¨ Ø£ÙˆØ±ÙˆØ¨Ø§ØŒ ØªØ¹ØªØ¨Ø± Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø¯ÙˆÙ„ Ø§Ù„Ø£Ø±Ø¨Ø¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø© Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©. ØªØ­ØªÙ„ Ø§Ù„Ø«Ù„Ø« Ø§Ù„Ø´Ù…Ø§Ù„ÙŠ Ù…Ù† Ø¬Ø²ÙŠØ±Ø© Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ§ Ø§Ù„Ø¹Ø¸Ù…Ù‰ ÙˆØªØ­Ø¯Ù‡Ø§ Ø¬Ù†ÙˆØ¨Ø§ Ø¥Ù†Ø¬Ù„ØªØ±Ø§ ÙˆÙŠØ­Ø¯Ù‡Ø§ Ø´Ø±Ù‚Ø§ Ø¨Ø­Ø± Ø§Ù„Ø´Ù…Ø§Ù„ ÙˆØºØ±Ø¨Ø§ Ø§Ù„Ù…Ø­ÙŠØ· Ø§Ù„Ø£Ø·Ù„Ø³ÙŠ. Ø¹Ø§ØµÙ…ØªÙ‡Ø§ Ø£Ø¯Ù†Ø¨Ø±Ø©ØŒ ÙˆØ£Ù‡Ù… Ù…Ø¯Ù†Ù‡Ø§ ÙˆØ£ÙƒØ¨Ø±Ù‡Ø§ Ù…Ø¯ÙŠÙ†Ø© ØºÙ„Ø§Ø³ÙƒÙˆ. ÙƒØ§Ù†Øª Ø§Ø³ÙƒØªÙ„Ù†Ø¯Ø§ Ù…Ù…Ù„ÙƒØ© Ù…Ø³ØªÙ‚Ù„Ø© Ø­ØªÙ‰ 1 Ù…Ø§ÙŠÙˆ 1707  answer:  Ø£Ø¯Ù†Ø¨Ø±Ø©  </s>"

- text: "context: Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ Ø£Ø¯ÙˆÙ„Ù Ù‡ØªÙ„Ø± ÙÙŠ 30 Ø£Ø¨Ø±ÙŠÙ„ 1945 Ù…Ù†ØªØ­Ø±Ø§ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªÙ†Ø§ÙˆÙ„ Ù…Ø§Ø¯Ø© Ø§Ù„Ø³ÙŠØ§Ù†ÙŠØ¯ Ø§Ù„Ø³Ø§Ù…Ø© ÙˆØ¥Ø·Ù„Ø§Ù‚ Ø§Ù„Ù†Ø§Ø± Ø¹Ù„Ù‰ Ù†ÙØ³Ù‡ ÙˆÙ‡ÙŠ Ø§Ù„Ø±ÙˆØ§ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„Ø© Ù„Ø·Ø±ÙŠÙ‚Ø© Ù…ÙˆØª Ø§Ù„Ø²Ø¹ÙŠÙ… Ø§Ù„Ù†Ø§Ø²ÙŠ answer: Ù…Ù†ØªØ­Ø±Ø§ </s>
"
metrics:
- bleu
model-index:
- name: Arabic-Question-Generation
  results:
  - task:
      name: Question-Generation
      type: automatic-question-generation
    metrics:
    - name: Bleu1
      type: bleu
      value: 37.62
    - name: Bleu2
      type: bleu
      value: 27.80
    - name: Bleu3
      type: bleu
      value: 20.89
    - name: Bleu4
      type: bleu
      value: 15.87
    - name: meteor
      type: meteor
      value: 33.19
    - name: rougel
      type: rouge
      value: 43.37
      

---
# Arabic Question Generation Model

This model is ready to use for **Question Generation** task, simply input the text and answer, the model will generate a question, This model is a fine-tuned version of [AraT5-Base](https://huggingface.co/UBC-NLP/AraT5-base)

## Live Demo 
Get the Question from given Context and a Answer : [Arabic QG Model](https://huggingface.co/spaces/Mihakram/Arabic_Question_Generation)

## Model in Action ğŸš€
```python
#Requirements !pip install transformers
from transformers import AutoTokenizer,AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained("Mihakram/AraT5-base-question-generation")
tokenizer = AutoTokenizer.from_pretrained("Mihakram/AraT5-base-question-generation")

def get_question(context,answer):
  text="context: " +context + " " + "answer: " + answer + " </s>"
  text_encoding = tokenizer.encode_plus(
      text,return_tensors="pt"
  )
  model.eval()
  generated_ids =  model.generate(
    input_ids=text_encoding['input_ids'],
    attention_mask=text_encoding['attention_mask'],
    max_length=64,
    num_beams=5,
    num_return_sequences=1
  )
  return tokenizer.decode(generated_ids[0],skip_special_tokens=True,clean_up_tokenization_spaces=True).replace('question: ',' ')

context="Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠØ© Ø£Ùˆ Ø«ÙˆØ±Ø© Ø§Ù„Ù…Ù„ÙŠÙˆÙ† Ø´Ù‡ÙŠØ¯ØŒ Ø§Ù†Ø¯Ù„Ø¹Øª ÙÙŠ 1 Ù†ÙˆÙÙ…Ø¨Ø± 1954 Ø¶Ø¯ Ø§Ù„Ù…Ø³ØªØ¹Ù…Ø± Ø§Ù„ÙØ±Ù†Ø³ÙŠ ÙˆØ¯Ø§Ù…Øª 7 Ø³Ù†ÙˆØ§Øª ÙˆÙ†ØµÙ. Ø§Ø³ØªØ´Ù‡Ø¯ ÙÙŠÙ‡Ø§ Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ù„ÙŠÙˆÙ† ÙˆÙ†ØµÙ Ù…Ù„ÙŠÙˆÙ† Ø¬Ø²Ø§Ø¦Ø±ÙŠ"
answer =" 7 Ø³Ù†ÙˆØ§Øª ÙˆÙ†ØµÙ"

get_question(context,answer)

#output : question="ÙƒÙ… Ø§Ø³ØªÙ…Ø±Øª Ø§Ù„Ø«ÙˆØ±Ø© Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠØ©ØŸ " 

```




## Citation
If you want to cite this model you can use this:
## Contacts
**Mihoubi Akram Fawzi**: [Linkedin](https://www.linkedin.com/in/mihoubi-akram/) | [Github](https://github.com/mihoubi-akram) | <mihhakram@gmail.com>

**Ibrir Adel**: [Linkedin]() | [Github]() | <adelibrir2015@gmail.com>

