{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27383</td>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110083</td>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140764</td>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100071</td>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2837</td>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text emotions\n",
       "0   27383  i feel awful about it too because it s my job ...  sadness\n",
       "1  110083                              im alone i feel awful  sadness\n",
       "2  140764  ive probably mentioned this before but i reall...      joy\n",
       "3  100071           i was feeling a little low few days back  sadness\n",
       "4    2837  i beleive that i am much more sensitive to oth...     love"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv(path: str) -> pd.DataFrame:\n",
    "    file = pd.read_csv(path)\n",
    "    return file\n",
    "\n",
    "TRAIN_SET = read_csv(\"./train.csv\")\n",
    "TEST_SET = read_csv(\"./test.csv\")\n",
    "TRAIN_SET.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         412\n",
       "sadness     351\n",
       "anger       161\n",
       "fear        129\n",
       "love        106\n",
       "surprise     41\n",
       "Name: emotions, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TRAIN_SET\n",
    "dataset.emotions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i feel awful about it too because it s my job to get him in a position to succeed and it just didn t happen here',\n",
       "  'im alone i feel awful\\t'],\n",
       " ['sadness', 'sadness'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_js = [\n",
    "    {\n",
    "        \"id\": 27383,\n",
    "        \"text\": \"i feel awful about it too because it s my job to get him in a position to succeed and it just didn t happen here\",\n",
    "        \"emotion\": \"sadness\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 110083,\n",
    "        \"text\": \"im alone i feel awful\t\",\n",
    "        \"emotion\": \"sadness\"\n",
    "    }\n",
    "]\n",
    "# \n",
    "dataset = dataset_js\n",
    "texts = [entry['text'] for entry in dataset_js]\n",
    "emotions = [entry['emotion'] for entry in dataset_js]\n",
    "texts, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'sadness': 0}, {0: 'sadness'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_set = set(emotions)\n",
    "emotion_to_int = {emotion: i for i, emotion in enumerate(emotion_set)}\n",
    "int_to_emotion = {i: emotion for i, emotion in enumerate(emotion_set)}\n",
    "emotion_to_int, int_to_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:53:00.609 | INFO     | __main__:<module>:15 - 4895\n"
     ]
    }
   ],
   "source": [
    "word2vec = {}\n",
    "word_set = {}\n",
    "word_all = []\n",
    "idx = 0\n",
    "for dataset in (TRAIN_SET, TEST_SET):\n",
    "    for text in dataset.text:\n",
    "        words = text.split()\n",
    "        for word in words:\n",
    "            if word not in word2vec:\n",
    "                word_all.append(word)\n",
    "                word2vec[word] = idx\n",
    "                idx += 1\n",
    "    word_set = set(word_all)\n",
    "    # logger.debug(idx)\n",
    "logger.info(len(word2vec))\n",
    "# logger.info(len(word_set))\n",
    "    # print(text)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 15:09:05.257 | INFO     | __main__:<module>:8 - 4895\n",
      "2023-02-13 15:09:05.259 | INFO     | __main__:<module>:9 - 1200\n"
     ]
    }
   ],
   "source": [
    "text_features_train = []\n",
    "for text in TRAIN_SET.text:\n",
    "    features = [0] * len(word2vec)\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        features[word2vec[word]] = 1\n",
    "    text_features_train.append(features)\n",
    "logger.info(len(text_features_train[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 15:09:05.904 | INFO     | __main__:<module>:8 - 4895\n",
      "2023-02-13 15:09:05.905 | INFO     | __main__:<module>:9 - 800\n"
     ]
    }
   ],
   "source": [
    "text_features_test = []\n",
    "for text in TEST_SET.text:\n",
    "    features = [0] * len(word2vec)\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        features[word2vec[word]] = 1\n",
    "    text_features_test.append(features)\n",
    "logger.info(len(text_features_test[0]))\n",
    "logger.info(len(text_features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [_ for _ in TRAIN_SET.emotions]\n",
    "# emotions_test = [_ for _ in TEST_SET.emotions]\n",
    "\n",
    "# emotion_set = set(emotions)\n",
    "emotion_set = set(emotions)\n",
    "\n",
    "emotion_to_int = {emotion: i for i, emotion in enumerate(emotion_set)}\n",
    "int_to_emotion = {i: emotion for i, emotion in enumerate(emotion_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [emotion_to_int[emotion] for emotion in emotions]\n",
    "train_targets = np.zeros((len(emotions), len(emotion_set)))\n",
    "for i, emotion in enumerate(emotions):\n",
    "    train_targets[i, emotion] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 4895)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(text_features_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 15:12:26.809 | INFO     | __main__:<module>:12 - Epoch = 0\n",
      "2023-02-13 15:12:27.490 | INFO     | __main__:<module>:12 - Epoch = 1\n",
      "2023-02-13 15:12:28.124 | INFO     | __main__:<module>:12 - Epoch = 2\n",
      "2023-02-13 15:12:28.764 | INFO     | __main__:<module>:12 - Epoch = 3\n",
      "2023-02-13 15:12:29.396 | INFO     | __main__:<module>:12 - Epoch = 4\n",
      "2023-02-13 15:12:30.028 | INFO     | __main__:<module>:12 - Epoch = 5\n",
      "2023-02-13 15:12:30.669 | INFO     | __main__:<module>:12 - Epoch = 6\n",
      "2023-02-13 15:12:31.312 | INFO     | __main__:<module>:12 - Epoch = 7\n",
      "2023-02-13 15:12:31.951 | INFO     | __main__:<module>:12 - Epoch = 8\n",
      "2023-02-13 15:12:32.584 | INFO     | __main__:<module>:12 - Epoch = 9\n",
      "2023-02-13 15:12:33.215 | INFO     | __main__:<module>:12 - Epoch = 10\n",
      "2023-02-13 15:12:33.844 | INFO     | __main__:<module>:12 - Epoch = 11\n",
      "2023-02-13 15:12:34.460 | INFO     | __main__:<module>:12 - Epoch = 12\n",
      "2023-02-13 15:12:35.123 | INFO     | __main__:<module>:12 - Epoch = 13\n",
      "2023-02-13 15:12:35.833 | INFO     | __main__:<module>:12 - Epoch = 14\n",
      "2023-02-13 15:12:36.480 | INFO     | __main__:<module>:12 - Epoch = 15\n",
      "2023-02-13 15:12:37.104 | INFO     | __main__:<module>:12 - Epoch = 16\n",
      "2023-02-13 15:12:37.735 | INFO     | __main__:<module>:12 - Epoch = 17\n",
      "2023-02-13 15:12:38.365 | INFO     | __main__:<module>:12 - Epoch = 18\n",
      "2023-02-13 15:12:38.987 | INFO     | __main__:<module>:12 - Epoch = 19\n",
      "2023-02-13 15:12:39.621 | INFO     | __main__:<module>:12 - Epoch = 20\n",
      "2023-02-13 15:12:40.244 | INFO     | __main__:<module>:12 - Epoch = 21\n",
      "2023-02-13 15:12:40.871 | INFO     | __main__:<module>:12 - Epoch = 22\n",
      "2023-02-13 15:12:41.538 | INFO     | __main__:<module>:12 - Epoch = 23\n",
      "2023-02-13 15:12:42.163 | INFO     | __main__:<module>:12 - Epoch = 24\n",
      "2023-02-13 15:12:42.792 | INFO     | __main__:<module>:12 - Epoch = 25\n",
      "2023-02-13 15:12:43.422 | INFO     | __main__:<module>:12 - Epoch = 26\n",
      "2023-02-13 15:12:44.051 | INFO     | __main__:<module>:12 - Epoch = 27\n",
      "2023-02-13 15:12:44.680 | INFO     | __main__:<module>:12 - Epoch = 28\n",
      "2023-02-13 15:12:45.314 | INFO     | __main__:<module>:12 - Epoch = 29\n",
      "2023-02-13 15:12:45.939 | INFO     | __main__:<module>:12 - Epoch = 30\n",
      "2023-02-13 15:12:46.616 | INFO     | __main__:<module>:12 - Epoch = 31\n",
      "2023-02-13 15:12:47.262 | INFO     | __main__:<module>:12 - Epoch = 32\n",
      "2023-02-13 15:12:47.913 | INFO     | __main__:<module>:12 - Epoch = 33\n",
      "2023-02-13 15:12:48.549 | INFO     | __main__:<module>:12 - Epoch = 34\n",
      "2023-02-13 15:12:49.194 | INFO     | __main__:<module>:12 - Epoch = 35\n",
      "2023-02-13 15:12:49.840 | INFO     | __main__:<module>:12 - Epoch = 36\n",
      "2023-02-13 15:12:50.483 | INFO     | __main__:<module>:12 - Epoch = 37\n",
      "2023-02-13 15:12:51.112 | INFO     | __main__:<module>:12 - Epoch = 38\n",
      "2023-02-13 15:12:51.731 | INFO     | __main__:<module>:12 - Epoch = 39\n",
      "2023-02-13 15:12:52.370 | INFO     | __main__:<module>:12 - Epoch = 40\n",
      "2023-02-13 15:12:53.018 | INFO     | __main__:<module>:12 - Epoch = 41\n",
      "2023-02-13 15:12:53.665 | INFO     | __main__:<module>:12 - Epoch = 42\n",
      "2023-02-13 15:12:54.308 | INFO     | __main__:<module>:12 - Epoch = 43\n",
      "2023-02-13 15:12:54.934 | INFO     | __main__:<module>:12 - Epoch = 44\n",
      "2023-02-13 15:12:55.547 | INFO     | __main__:<module>:12 - Epoch = 45\n",
      "2023-02-13 15:12:56.166 | INFO     | __main__:<module>:12 - Epoch = 46\n",
      "2023-02-13 15:12:56.810 | INFO     | __main__:<module>:12 - Epoch = 47\n",
      "2023-02-13 15:12:57.443 | INFO     | __main__:<module>:12 - Epoch = 48\n",
      "2023-02-13 15:12:58.068 | INFO     | __main__:<module>:12 - Epoch = 49\n",
      "2023-02-13 15:12:58.684 | INFO     | __main__:<module>:12 - Epoch = 50\n",
      "2023-02-13 15:12:59.308 | INFO     | __main__:<module>:12 - Epoch = 51\n",
      "2023-02-13 15:12:59.930 | INFO     | __main__:<module>:12 - Epoch = 52\n",
      "2023-02-13 15:13:00.579 | INFO     | __main__:<module>:12 - Epoch = 53\n",
      "2023-02-13 15:13:01.232 | INFO     | __main__:<module>:12 - Epoch = 54\n",
      "2023-02-13 15:13:01.851 | INFO     | __main__:<module>:12 - Epoch = 55\n",
      "2023-02-13 15:13:02.471 | INFO     | __main__:<module>:12 - Epoch = 56\n",
      "2023-02-13 15:13:03.102 | INFO     | __main__:<module>:12 - Epoch = 57\n",
      "2023-02-13 15:13:03.725 | INFO     | __main__:<module>:12 - Epoch = 58\n",
      "2023-02-13 15:13:04.333 | INFO     | __main__:<module>:12 - Epoch = 59\n",
      "2023-02-13 15:13:04.934 | INFO     | __main__:<module>:12 - Epoch = 60\n",
      "2023-02-13 15:13:05.549 | INFO     | __main__:<module>:12 - Epoch = 61\n",
      "2023-02-13 15:13:06.164 | INFO     | __main__:<module>:12 - Epoch = 62\n",
      "2023-02-13 15:13:06.786 | INFO     | __main__:<module>:12 - Epoch = 63\n",
      "2023-02-13 15:13:07.408 | INFO     | __main__:<module>:12 - Epoch = 64\n",
      "2023-02-13 15:13:08.030 | INFO     | __main__:<module>:12 - Epoch = 65\n",
      "2023-02-13 15:13:08.648 | INFO     | __main__:<module>:12 - Epoch = 66\n",
      "2023-02-13 15:13:09.275 | INFO     | __main__:<module>:12 - Epoch = 67\n",
      "2023-02-13 15:13:09.902 | INFO     | __main__:<module>:12 - Epoch = 68\n",
      "2023-02-13 15:13:10.524 | INFO     | __main__:<module>:12 - Epoch = 69\n",
      "2023-02-13 15:13:11.165 | INFO     | __main__:<module>:12 - Epoch = 70\n",
      "2023-02-13 15:13:11.796 | INFO     | __main__:<module>:12 - Epoch = 71\n",
      "2023-02-13 15:13:12.422 | INFO     | __main__:<module>:12 - Epoch = 72\n",
      "2023-02-13 15:13:13.084 | INFO     | __main__:<module>:12 - Epoch = 73\n",
      "2023-02-13 15:13:13.704 | INFO     | __main__:<module>:12 - Epoch = 74\n",
      "2023-02-13 15:13:14.338 | INFO     | __main__:<module>:12 - Epoch = 75\n",
      "2023-02-13 15:13:14.959 | INFO     | __main__:<module>:12 - Epoch = 76\n",
      "2023-02-13 15:13:15.601 | INFO     | __main__:<module>:12 - Epoch = 77\n",
      "2023-02-13 15:13:16.249 | INFO     | __main__:<module>:12 - Epoch = 78\n",
      "2023-02-13 15:13:17.073 | INFO     | __main__:<module>:12 - Epoch = 79\n",
      "2023-02-13 15:13:17.848 | INFO     | __main__:<module>:12 - Epoch = 80\n",
      "2023-02-13 15:13:18.587 | INFO     | __main__:<module>:12 - Epoch = 81\n",
      "2023-02-13 15:13:19.425 | INFO     | __main__:<module>:12 - Epoch = 82\n",
      "2023-02-13 15:13:20.181 | INFO     | __main__:<module>:12 - Epoch = 83\n",
      "2023-02-13 15:13:20.921 | INFO     | __main__:<module>:12 - Epoch = 84\n",
      "2023-02-13 15:13:21.701 | INFO     | __main__:<module>:12 - Epoch = 85\n",
      "2023-02-13 15:13:22.374 | INFO     | __main__:<module>:12 - Epoch = 86\n",
      "2023-02-13 15:13:23.076 | INFO     | __main__:<module>:12 - Epoch = 87\n",
      "2023-02-13 15:13:23.802 | INFO     | __main__:<module>:12 - Epoch = 88\n",
      "2023-02-13 15:13:24.524 | INFO     | __main__:<module>:12 - Epoch = 89\n",
      "2023-02-13 15:13:25.184 | INFO     | __main__:<module>:12 - Epoch = 90\n",
      "2023-02-13 15:13:25.913 | INFO     | __main__:<module>:12 - Epoch = 91\n",
      "2023-02-13 15:13:26.661 | INFO     | __main__:<module>:12 - Epoch = 92\n",
      "2023-02-13 15:13:27.383 | INFO     | __main__:<module>:12 - Epoch = 93\n",
      "2023-02-13 15:13:28.107 | INFO     | __main__:<module>:12 - Epoch = 94\n",
      "2023-02-13 15:13:28.826 | INFO     | __main__:<module>:12 - Epoch = 95\n",
      "2023-02-13 15:13:29.546 | INFO     | __main__:<module>:12 - Epoch = 96\n",
      "2023-02-13 15:13:30.193 | INFO     | __main__:<module>:12 - Epoch = 97\n",
      "2023-02-13 15:13:30.879 | INFO     | __main__:<module>:12 - Epoch = 98\n",
      "2023-02-13 15:13:31.572 | INFO     | __main__:<module>:12 - Epoch = 99\n"
     ]
    }
   ],
   "source": [
    "weights = np.zeros((len(word2vec), len(emotion_set)))\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    scores = np.dot(np.array(text_features_train), weights)\n",
    "    predictions = 1 / (1 + np.exp(-scores))\n",
    "    # logger.debug(np.array(predictions).shape)\n",
    "    # logger.debug(np.array(train_targets).shape)\n",
    "    error = train_targets - predictions\n",
    "    gradient = np.dot(np.array(text_features_train).T, error)\n",
    "    weights += learning_rate * gradient\n",
    "    logger.info(f\"Epoch = {epoch}\")\n",
    "\n",
    "# Predict emotions for the test data\n",
    "scores = np.dot(text_features_test, weights)\n",
    "predictions = 1 / (1 + np.exp(-scores))\n",
    "predictions = np.round(predictions)\n",
    "predicted_emotion = int_to_emotion[np.argmax(predictions[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_emotion = []\n",
    "\n",
    "scores = np.dot(text_features_test, weights)\n",
    "predictions = 1 / (1 + np.exp(-scores))\n",
    "# logger.debug(predictions)\n",
    "# predictions = np.ones(predictions.shape) * np.argmax(predictions, axis=1)\n",
    "# len(np.argmax(predictions, axis=1))\n",
    "pred = np.zeros(predictions.shape)\n",
    "for idx in range(pred.shape[0]):\n",
    "    # logger.debug(np.argmax(predictions, axis=1)[idx])\n",
    "    pred[idx][np.argmax(predictions, axis=1)[idx]] = 1\n",
    "\n",
    "for idx in range(pred.shape[0]):\n",
    "    # logger.debug(np.where(pred[idx]==1))\n",
    "    \n",
    "    # logger.debug(int_to_emotion[np.where(pred[idx]==1)[0][0]])\n",
    "    pred_emotion.append(int_to_emotion[np.where(pred[idx]==1)[0][0]])\n",
    "# predictions = np.argmax(predictions)\n",
    "# predicted_emotion = int_to_emotion[np.argmax(predictions[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['emotions'] = pred_emotion\n",
    "dataset.to_csv(\"./test_lg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139312</td>\n",
       "      <td>ive been feeling more optimistic this week tha...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110362</td>\n",
       "      <td>i suppose i was feeling adventurous and volunt...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45691</td>\n",
       "      <td>i feel like when a cycle comes i get all depre...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>958</td>\n",
       "      <td>when confronted and in my opinion hassled by t...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33882</td>\n",
       "      <td>i seldom feel shaky mid run</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>566</td>\n",
       "      <td>that was what i felt when i was finally accept...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>36236</td>\n",
       "      <td>i take every day as it comes i m just focussin...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>76229</td>\n",
       "      <td>i just suddenly feel that everything was fake</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>131640</td>\n",
       "      <td>im feeling more eager than ever to claw back w...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>64703</td>\n",
       "      <td>i give you plenty of attention even when i fee...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text emotions\n",
       "0    139312  ive been feeling more optimistic this week tha...  sadness\n",
       "1    110362  i suppose i was feeling adventurous and volunt...      joy\n",
       "2     45691  i feel like when a cycle comes i get all depre...  sadness\n",
       "3       958  when confronted and in my opinion hassled by t...    anger\n",
       "4     33882                        i seldom feel shaky mid run     fear\n",
       "..      ...                                                ...      ...\n",
       "795     566  that was what i felt when i was finally accept...      joy\n",
       "796   36236  i take every day as it comes i m just focussin...  sadness\n",
       "797   76229      i just suddenly feel that everything was fake  sadness\n",
       "798  131640  im feeling more eager than ever to claw back w...      joy\n",
       "799   64703  i give you plenty of attention even when i fee...  sadness\n",
       "\n",
       "[800 rows x 3 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs577",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cce05cc41e51c76494075da45dd5ce6d27471df880765b5e87f79f8482f0d668"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
